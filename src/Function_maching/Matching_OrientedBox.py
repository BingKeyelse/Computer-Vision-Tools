from libs import*

def rotate_image_keep_all(img: np.ndarray, angle: float, borderValue: tuple[int, int, int] = (255, 255, 255)
    ) -> tuple[np.ndarray, tuple[int, int]]:
    """
    ## Xoay ·∫£nh quanh t√¢m nh∆∞ng v·∫´n gi·ªØ to√†n b·ªô n·ªôi dung (canvas m·ªü r·ªông)
    - input
        - img: ·∫£nh ƒë·∫ßu v√†o (numpy.ndarray)
        - angle: g√≥c xoay (ƒë·ªô, chi·ªÅu ng∆∞·ª£c kim ƒë·ªìng h·ªì)
        - borderValue: m√†u n·ªÅn vi·ªÅn khi m·ªü r·ªông canvas (m·∫∑c ƒë·ªãnh tr·∫Øng)
    - output
        - M: ma tr·∫≠n xoay 2x3 ƒë·ªÉ s·ª≠ d·ª•ng trong `cv2.warpAffine`
        - (new_w, new_h): k√≠ch th∆∞·ªõc m·ªõi c·ªßa ·∫£nh sau khi xoay
    - Ghi ch√∫
        - H√†m n√†y ch·ªâ t√≠nh to√°n ma tr·∫≠n v√† k√≠ch th∆∞·ªõc, kh√¥ng th·ª±c hi·ªán xoay.
        - D√πng khi c·∫ßn xoay ·∫£nh m√† kh√¥ng b·ªã m·∫•t ph·∫ßn n√†o c·ªßa n·ªôi dung.
    """
    (h, w) = img.shape[:2]
    angle_rad = np.deg2rad(angle)
    cos, sin = abs(np.cos(angle_rad)), abs(np.sin(angle_rad))
    new_w = int(h * sin + w * cos)
    new_h = int(h * cos + w * sin)
    M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)
    M[0, 2] += (new_w - w) / 2
    M[1, 2] += (new_h - h) / 2
    return M, (new_w, new_h)

def extract_oriented_object(img: np.ndarray, start: tuple, end: tuple, angle_rad:float
    )-> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    ## Chu·∫©n h√≥a v√πng oriented box (nghi√™ng) v·ªÅ h∆∞·ªõng n·∫±m ngang
    - input
        - img: ·∫£nh ƒë·∫ßu v√†o (numpy.ndarray)
        - start: t·ªça ƒë·ªô ƒëi·ªÉm ƒë·∫ßu (x1, y1)
        - end: t·ªça ƒë·ªô ƒëi·ªÉm ƒë·ªëi di·ªán ƒë∆∞·ªùng ch√©o (x2, y2)
        - angle_rad: g√≥c nghi√™ng c·ªßa box (radian)
    - output
        - cropped: v√πng ƒë·ªëi t∆∞·ª£ng ƒë√£ ƒë∆∞·ª£c xoay th·∫≥ng v√† crop ra
        - rotated: ·∫£nh to√†n c·∫£nh sau khi xoay to√†n b·ªô ƒë·ªÉ ‚Äúd·ª±ng th·∫≥ng‚Äù
        - box_rotated: t·ªça ƒë·ªô polygon 4 ƒë·ªânh c·ªßa box trong ·∫£nh ƒë√£ xoay
    - Gi·∫£i th√≠ch
        - H√†m n√†y d√πng ƒë·ªÉ x·ª≠ l√Ω template ho·∫∑c ƒë·ªëi t∆∞·ª£ng nghi√™ng (oriented box)
          v√† ƒë∆∞a n√≥ v·ªÅ h∆∞·ªõng chu·∫©n (n·∫±m ngang) ƒë·ªÉ d·ªÖ matching.
    """
    # Chuy·ªÉn g√≥c sang ƒë·ªô
    angle_deg = np.degrees(angle_rad)

    # T√¢m v√† k√≠ch th∆∞·ªõc box
    cx, cy = (start[0] + end[0]) / 2, (start[1] + end[1]) / 2
    w = abs(end[0] - start[0])
    h = abs(end[1] - start[1])

    # T·∫°o rotated rect (gi·ªëng cv2.minAreaRect)
    rect = ((cx, cy), (w, h), angle_deg)

    # L·∫•y 4 ƒëi·ªÉm polygon t·ª´ rect (theo h∆∞·ªõng nghi√™ng)
    box = cv2.boxPoints(rect).astype(np.float32)

    # --- T·∫°o ma tr·∫≠n xoay ƒë·ªÉ "d·ª±ng th·∫≥ng" box ---
    M = cv2.getRotationMatrix2D((cx, cy), angle_deg, 1.0)
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])

    # T√≠nh k√≠ch th∆∞·ªõc m·ªõi sau khi xoay to√†n ·∫£nh
    h_img, w_img = img.shape[:2]
    new_w = int(h_img * sin + w_img * cos)
    new_h = int(h_img * cos + w_img * sin)

    # C·∫≠p nh·∫≠t offset ƒë·ªÉ kh√¥ng b·ªã crop ngo√†i
    M[0, 2] += (new_w / 2) - cx
    M[1, 2] += (new_h / 2) - cy

    # Xoay to√†n ·∫£nh ƒë·ªÉ ƒë·ªëi t∆∞·ª£ng v·ªÅ th·∫≥ng
    rotated = cv2.warpAffine(img, M, (new_w, new_h), flags=cv2.INTER_LINEAR, borderValue=(255, 255, 255))

    # Chuy·ªÉn box ƒëi·ªÉm sang kh√¥ng gian m·ªõi (sau khi xoay)
    ones = np.ones((4, 1), dtype=np.float32)
    box_h = np.hstack([box, ones])
    box_rotated = (M @ box_h.T).T

    # Crop v√πng bounding box m·ªõi
    x_min, y_min = box_rotated[:, 0].min(), box_rotated[:, 1].min()
    x_max, y_max = box_rotated[:, 0].max(), box_rotated[:, 1].max()

    cropped = rotated[int(y_min):int(y_max), int(x_min):int(x_max)]
    return cropped, rotated, box_rotated.astype(np.int32)


# ================ OrientedBoxMatcher ================
class OrientedBoxMatcher(BaseMatcher):  
    """
    ## L·ªõp x·ª≠ l√Ω template matching cho v√πng oriented box (nghi√™ng).
    - T·ª± ƒë·ªông d·ª±ng th·∫≥ng template v√† qu√©t ƒëa g√≥c (coarse ‚Üí refine).
    """
    def __init__(self, temple_path: str, data: list, scale: float):
        """
        - input:
            - temple_path: ƒë∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh template
            - data: th√¥ng tin v√πng oriented box (x1, y1, x2, y2, angle)
            - scale: t·ªâ l·ªá ph√≥ng template
        """
        super().__init__(temple_path, data, scale)
        self.template: np.ndarray | None = None

    def load_template(self)-> np.ndarray:
        """
        ## Load v√† d·ª±ng th·∫≥ng v√πng oriented box trong template.
        - output:
            - template ƒë√£ ƒë∆∞·ª£c d·ª±ng th·∫≥ng, resize theo scale
        """
        _, (x1, y1), (x2, y2), angle = self.data
        img = cv2.imread(self.temple_path, cv2.IMREAD_GRAYSCALE)

        self.template, rotated, box_rotated = extract_oriented_object(img, (x1, y1), (x2, y2), angle)

        ## Test
        # V·∫Ω v√πng oriented box sau xoay
        # V·∫Ω v√πng oriented box sau xoay
        # vis = rotated.copy()
        # cv2.polylines(vis, [box_rotated], isClosed=True, color=(0, 255, 0), thickness=2)
        # vis= cv2.resize(vis, (0,0), fx= 0.5, fy=0.5)
        # cv2.imshow("Rotated Scene", vis)
        # cv2.imshow("Aligned Crop", self.template)
        # cv2.waitKey(0)
        # cv2.destroyAllWindows()
        #
        self.template = cv2.resize(self.template, (0,0), fx= self.scale, fy= self.scale)
        return self.template

    def match(
        self,
        scene: np.ndarray,
        coarse_scale: float = 0.3,
        coarse_step: int = 10,
        refine_step: int = 2,
        threshold: float = 0.7,
        max_candidates: int = 15,
        max_objects: int = 5,
        pad: int = 20
    ) -> list[dict[str, float | list[int]]]:
        """
        ## D√≤ t√¨m template h√¨nh h·ªôp ch·ªØ nh·∫≠t trong scene (qu√©t coarse ‚Üí refine).
        - input:
            - scene: ·∫£nh g·ªëc c·∫ßn d√≤ t√¨m
            - coarse_scale: t·ªâ l·ªá gi·∫£m k√≠ch th∆∞·ªõc ·∫£nh cho b∆∞·ªõc coarse
            - coarse_step: b∆∞·ªõc xoay g√≥c trong giai ƒëo·∫°n coarse
            - refine_step: b∆∞·ªõc xoay tinh trong refine
            - threshold: ng∆∞·ª°ng t∆∞∆°ng quan t·ªëi thi·ªÉu
            - max_candidates: s·ªë l∆∞·ª£ng ·ª©ng vi√™n t·ªëi ƒëa ƒë·ªÉ refine
            - max_objects: s·ªë ƒë·ªëi t∆∞·ª£ng gi·ªØ l·∫°i sau NMS
            - pad: v√πng ƒë·ªám quanh box khi refine
        - output:
            - Danh s√°ch dict ch·ª©a:
                - "box": [x1, y1, x2, y2]
                - "angle": g√≥c t√¨m th·∫•y (ƒë·ªô)
                - "score": ƒë·ªô t∆∞∆°ng ƒë·ªìng
        """
        if self.template is None:
            self.load_template()
        template = self.template

        t0 = time.time()

        print("üåÄ [COARSE] scanning...")
        small_scene = cv2.resize(scene, (0, 0), fx=coarse_scale, fy=coarse_scale)
        small_template = cv2.resize(template, (0, 0), fx=coarse_scale, fy=coarse_scale)
        
        # small_scene = cv2.GaussianBlur(small_scene, (3, 3), 0)
        # small_template = cv2.GaussianBlur(small_template, (3, 3), 0)

        # 2. L√†m m∆∞·ª£t ƒë·ªÉ gi·∫£m v√πng bi√™n tr·∫Øng
        small_scene = cv2.bilateralFilter(small_scene, 5, 50, 50)
        small_template = cv2.bilateralFilter(small_template, 5, 50, 50)

        # 3. C√¢n s√°ng
        small_scene = cv2.equalizeHist(small_scene)
        small_template = cv2.equalizeHist(small_template)

        angles = np.arange(0, 360, coarse_step)
        all_boxes, all_scores, all_angles = [], [], []

        for angle in angles:
            M, (new_w, new_h) = rotate_image_keep_all(small_template, angle)
            rotated_temple = cv2.warpAffine(
                small_template, M, (new_w, new_h),
                flags=cv2.INTER_LINEAR, borderValue=(255, 255, 255)
            )
            if rotated_temple.shape[0] > small_scene.shape[0] or rotated_temple.shape[1] > small_scene.shape[1]:
                continue

            res = cv2.matchTemplate(small_scene, rotated_temple, cv2.TM_CCOEFF_NORMED)
            loc = np.where(res >= threshold)
            for pt in zip(*loc[::-1]):
                all_boxes.append([pt[0], pt[1], pt[0] + new_w, pt[1] + new_h])
                all_scores.append(float(res[pt[1], pt[0]]))
                all_angles.append(angle)

        if not all_boxes:
            print("‚ùå Kh√¥ng c√≥ v√πng v∆∞·ª£t ng∆∞·ª°ng coarse.")
            return []

        keep = cv2.dnn.NMSBoxes(all_boxes, all_scores, score_threshold=threshold, nms_threshold=0.3)
        if len(keep) == 0:
            return []

        keep = sorted(keep.flatten(), key=lambda i: all_scores[i], reverse=True)[:max_candidates]
        coarse_candidates = []
        for i in keep:
            x1, y1, x2, y2 = np.array(all_boxes[i]) / coarse_scale
            coarse_candidates.append({
                "box": [int(x1), int(y1), int(x2), int(y2)],
                "angle": all_angles[i],
                "score": all_scores[i]
            })

        print(f"‚úÖ [COARSE] {len(coarse_candidates)} candidates ‚Üí refine")
        refine_results = []

        for candidate in coarse_candidates:
            x1, y1, x2, y2 = candidate["box"]
            angle_c = candidate["angle"]

            x1p, y1p = max(0, x1 - pad), max(0, y1 - pad)
            x2p, y2p = min(scene.shape[1], x2 + pad), min(scene.shape[0], y2 + pad)
            roi = scene[y1p:y2p, x1p:x2p]
            if roi.size == 0:
                continue

            best_local = None
            local_angles = np.arange(angle_c - 15, angle_c + 15 + 1, refine_step)
            for a in local_angles:
                M, (new_w, new_h) = rotate_image_keep_all(template, a)
                rotated_t = cv2.warpAffine(template, M, (new_w, new_h),
                                           flags=cv2.INTER_LINEAR, borderValue=(255, 255, 255))
                if rotated_t.shape[0] > roi.shape[0] or rotated_t.shape[1] > roi.shape[1]:
                    continue

                res = cv2.matchTemplate(roi, rotated_t, cv2.TM_CCOEFF_NORMED) 
                _, max_val, _, max_loc = cv2.minMaxLoc(res)
                if max_val < threshold:
                    continue

                abs_loc = (max_loc[0] + x1p, max_loc[1] + y1p)
                if (best_local is None) or (max_val > best_local["score"]):
                    best_local = {
                        "shape": "oriented_box",
                        "box": [abs_loc[0], abs_loc[1],
                                abs_loc[0] + new_w, abs_loc[1] + new_h],
                        "angle": a,
                        "score": max_val
                    }

            if best_local:
                refine_results.append(best_local)

        if not refine_results:
            print("‚ùå Kh√¥ng c√≥ refine result.")
            return []

        boxes = [r["box"] for r in refine_results]
        scores = [r["score"] for r in refine_results]
        keep = cv2.dnn.NMSBoxes(boxes, scores, score_threshold=threshold, nms_threshold=0.3)
        if len(keep) == 0:
            return []

        keep = sorted(keep.flatten(), key=lambda i: scores[i], reverse=True)[:max_objects]

        print(f"‚úÖ [REFINE] gi·ªØ l·∫°i {len(keep)} ƒë·ªëi t∆∞·ª£ng.")
        print(f"‚è± T·ªïng th·ªùi gian: {time.time() - t0:.2f}s")

        return [refine_results[i] for i in keep]


